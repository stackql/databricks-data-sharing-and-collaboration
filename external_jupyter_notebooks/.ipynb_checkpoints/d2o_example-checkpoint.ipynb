{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de43bb54",
   "metadata": {},
   "source": [
    "# D2O Delta Sharing - Recipient Demo\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to access Databricks Delta Sharing data as an **open recipient** (non-Databricks user). \n",
    "\n",
    "In this demo, we'll:\n",
    "1. Load credentials from the config file\n",
    "2. Connect to the Delta Share\n",
    "3. List available shares and tables\n",
    "4. Query the shared data using pandas\n",
    "5. Create visualizations using seaborn\n",
    "\n",
    "**Prerequisites:**\n",
    "- The provider has created a share and recipient\n",
    "- You have received the credential file (`config.share`)\n",
    "- This notebook is running in a Docker container with the necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271986b",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cc4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import delta_sharing\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Configure matplotlib and seaborn\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(f\"Delta Sharing version: {delta_sharing.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb013a92",
   "metadata": {},
   "source": [
    "## Step 2: Load Delta Sharing Credentials\n",
    "\n",
    "The credentials are passed via environment variable `DELTA_SHARING_CONFIG` which contains the JSON configuration from the `config.share` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials from environment variable\n",
    "config_json = os.environ.get('DELTA_SHARING_CONFIG')\n",
    "\n",
    "if not config_json:\n",
    "    raise ValueError(\"DELTA_SHARING_CONFIG environment variable not set!\")\n",
    "\n",
    "# Parse the configuration\n",
    "config = json.loads(config_json)\n",
    "\n",
    "# Write to a temporary file (delta-sharing library requires a file path)\n",
    "config_file_path = '/tmp/config.share'\n",
    "with open(config_file_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"✓ Credentials loaded successfully\")\n",
    "print(f\"Endpoint: {config['endpoint']}\")\n",
    "print(f\"Token expires: {config.get('expirationTime', 'N/A')}\")\n",
    "\n",
    "# Create a SharingClient\n",
    "client = delta_sharing.SharingClient(config_file_path)\n",
    "print(\"✓ Delta Sharing client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da111374",
   "metadata": {},
   "source": [
    "## Step 3: List Available Shares\n",
    "\n",
    "Let's discover what shares are available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available shares\n",
    "shares = client.list_shares()\n",
    "\n",
    "print(f\"✓ Found {len(shares)} share(s)\\n\")\n",
    "for share in shares:\n",
    "    print(f\"Share: {share.name}\")\n",
    "    if hasattr(share, 'id'):\n",
    "        print(f\"  ID: {share.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b1639c",
   "metadata": {},
   "source": [
    "## Step 4: List Schemas in the Share\n",
    "\n",
    "Now let's see what schemas (databases) are available in the share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first share (assuming it's the external_retail share)\n",
    "share_name = shares[0].name\n",
    "print(f\"Working with share: {share_name}\\n\")\n",
    "\n",
    "# List schemas in the share\n",
    "schemas = client.list_schemas(delta_sharing.Share(name=share_name))\n",
    "\n",
    "print(f\"✓ Found {len(schemas)} schema(s)\\n\")\n",
    "for schema in schemas:\n",
    "    print(f\"Schema: {schema.name}\")\n",
    "    if hasattr(schema, 'share'):\n",
    "        print(f\"  Share: {schema.share}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9af2b76",
   "metadata": {},
   "source": [
    "## Step 5: List Tables in the Schema\n",
    "\n",
    "Let's see what tables are available for us to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe636973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first schema\n",
    "schema_name = schemas[0].name\n",
    "print(f\"Working with schema: {schema_name}\\n\")\n",
    "\n",
    "# List all tables in the schema\n",
    "tables = client.list_tables(delta_sharing.Schema(name=schema_name, share=share_name))\n",
    "\n",
    "print(f\"✓ Found {len(tables)} table(s)\\n\")\n",
    "for i, table in enumerate(tables, 1):\n",
    "    print(f\"{i}. Table: {table.name}\")\n",
    "    if hasattr(table, 'share'):\n",
    "        print(f\"   Share: {table.share}\")\n",
    "    if hasattr(table, 'schema'):\n",
    "        print(f\"   Schema: {table.schema}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1268e84",
   "metadata": {},
   "source": [
    "## Step 6: Query the Customers Table\n",
    "\n",
    "Let's load the customers table into a pandas DataFrame and explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f9981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct table URL for customers\n",
    "customers_table_url = f\"{config_file_path}#{share_name}.{schema_name}.customers\"\n",
    "\n",
    "# Load the table into a pandas DataFrame\n",
    "print(\"Loading customers table...\")\n",
    "customers_df = delta_sharing.load_as_pandas(customers_table_url)\n",
    "\n",
    "print(f\"✓ Loaded {len(customers_df)} customer records\\n\")\n",
    "print(\"Data shape:\", customers_df.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(customers_df.columns.tolist())\n",
    "print(\"\\nFirst few records:\")\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96ab01",
   "metadata": {},
   "source": [
    "## Step 7: Query the Sales Transactions Table\n",
    "\n",
    "Now let's load the sales transactions data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct table URL for sales transactions\n",
    "sales_table_url = f\"{config_file_path}#{share_name}.{schema_name}.sales_transactions\"\n",
    "\n",
    "# Load the table into a pandas DataFrame\n",
    "print(\"Loading sales transactions table...\")\n",
    "sales_df = delta_sharing.load_as_pandas(sales_table_url)\n",
    "\n",
    "print(f\"✓ Loaded {len(sales_df)} transaction records\\n\")\n",
    "print(\"Data shape:\", sales_df.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(sales_df.columns.tolist())\n",
    "print(\"\\nFirst few records:\")\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3985d9",
   "metadata": {},
   "source": [
    "## Step 8: Data Analysis and Summary Statistics\n",
    "\n",
    "Let's explore the data with some basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CUSTOMER DATA SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal customers: {len(customers_df):,}\")\n",
    "print(\"\\nCustomer info:\")\n",
    "print(customers_df.info())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SALES DATA SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal transactions: {len(sales_df):,}\")\n",
    "\n",
    "# Calculate basic statistics if amount column exists\n",
    "if 'amount' in sales_df.columns:\n",
    "    print(f\"Total revenue: ${sales_df['amount'].sum():,.2f}\")\n",
    "    print(f\"Average transaction: ${sales_df['amount'].mean():,.2f}\")\n",
    "    print(f\"Max transaction: ${sales_df['amount'].max():,.2f}\")\n",
    "    print(f\"Min transaction: ${sales_df['amount'].min():,.2f}\")\n",
    "    \n",
    "print(\"\\nSales data info:\")\n",
    "print(sales_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014aae63",
   "metadata": {},
   "source": [
    "## Step 9: Visualization 1 - Sales Distribution\n",
    "\n",
    "Let's create some visualizations using seaborn to better understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d2281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Sales Data Analysis Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Distribution of transaction amounts (if amount column exists)\n",
    "if 'amount' in sales_df.columns:\n",
    "    sns.histplot(data=sales_df, x='amount', bins=30, kde=True, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Distribution of Transaction Amounts')\n",
    "    axes[0, 0].set_xlabel('Transaction Amount ($)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Plot 2: Box plot of amounts\n",
    "    sns.boxplot(data=sales_df, y='amount', ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Transaction Amount Box Plot')\n",
    "    axes[0, 1].set_ylabel('Amount ($)')\n",
    "else:\n",
    "    axes[0, 0].text(0.5, 0.5, 'No amount column found', ha='center', va='center')\n",
    "    axes[0, 1].text(0.5, 0.5, 'No amount column found', ha='center', va='center')\n",
    "\n",
    "# Plot 3: Transaction count over time (if date column exists)\n",
    "date_cols = [col for col in sales_df.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "if date_cols:\n",
    "    date_col = date_cols[0]\n",
    "    sales_df[date_col] = pd.to_datetime(sales_df[date_col])\n",
    "    sales_by_date = sales_df.groupby(sales_df[date_col].dt.date).size()\n",
    "    axes[1, 0].plot(sales_by_date.index, sales_by_date.values, marker='o')\n",
    "    axes[1, 0].set_title('Transactions Over Time')\n",
    "    axes[1, 0].set_xlabel('Date')\n",
    "    axes[1, 0].set_ylabel('Number of Transactions')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'No date column found', ha='center', va='center')\n",
    "\n",
    "# Plot 4: Top customers by transaction count\n",
    "if 'customer_id' in sales_df.columns:\n",
    "    top_customers = sales_df['customer_id'].value_counts().head(10)\n",
    "    sns.barplot(x=top_customers.values, y=top_customers.index.astype(str), ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Top 10 Customers by Transaction Count')\n",
    "    axes[1, 1].set_xlabel('Number of Transactions')\n",
    "    axes[1, 1].set_ylabel('Customer ID')\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'No customer_id column found', ha='center', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualizations created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903253d",
   "metadata": {},
   "source": [
    "## Step 10: Visualization 2 - Customer Demographics\n",
    "\n",
    "Let's analyze customer demographics if the data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71539e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Customer Demographics Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Customer distribution by a categorical column (if exists)\n",
    "categorical_cols = customers_df.select_dtypes(include=['object']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    col = categorical_cols[0]\n",
    "    value_counts = customers_df[col].value_counts().head(10)\n",
    "    sns.barplot(x=value_counts.values, y=value_counts.index, ax=axes[0])\n",
    "    axes[0].set_title(f'Top 10 {col} Distribution')\n",
    "    axes[0].set_xlabel('Count')\n",
    "    axes[0].set_ylabel(col)\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'No categorical columns found', ha='center', va='center')\n",
    "\n",
    "# Plot 2: Pie chart of another categorical column if available\n",
    "if len(categorical_cols) > 1:\n",
    "    col = categorical_cols[1]\n",
    "    value_counts = customers_df[col].value_counts().head(8)\n",
    "    axes[1].pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title(f'{col} Distribution')\n",
    "elif len(categorical_cols) == 1:\n",
    "    # Use the same column but different visualization\n",
    "    col = categorical_cols[0]\n",
    "    value_counts = customers_df[col].value_counts()\n",
    "    axes[1].pie(value_counts.values[:8], labels=value_counts.index[:8], autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title(f'{col} Distribution (Pie Chart)')\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'No categorical columns found', ha='center', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Customer demographics visualizations created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce2268",
   "metadata": {},
   "source": [
    "## Step 11: Advanced Analysis - Merge and Analyze\n",
    "\n",
    "Let's join the customer and sales data for deeper insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b68e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to merge if customer_id exists in both dataframes\n",
    "if 'customer_id' in sales_df.columns and 'customer_id' in customers_df.columns:\n",
    "    merged_df = sales_df.merge(customers_df, on='customer_id', how='left')\n",
    "    \n",
    "    print(f\"✓ Merged dataset created with {len(merged_df)} records\")\n",
    "    print(f\"\\nMerged columns: {merged_df.columns.tolist()}\")\n",
    "    \n",
    "    # Calculate revenue by customer segment if applicable\n",
    "    if 'amount' in merged_df.columns:\n",
    "        # Group by any categorical customer column\n",
    "        cat_cols = [col for col in customers_df.columns if customers_df[col].dtype == 'object' and col != 'customer_id']\n",
    "        \n",
    "        if cat_cols:\n",
    "            segment_col = cat_cols[0]\n",
    "            revenue_by_segment = merged_df.groupby(segment_col)['amount'].agg(['sum', 'mean', 'count'])\n",
    "            revenue_by_segment.columns = ['Total Revenue', 'Avg Transaction', 'Transaction Count']\n",
    "            revenue_by_segment = revenue_by_segment.sort_values('Total Revenue', ascending=False)\n",
    "            \n",
    "            print(f\"\\nRevenue Analysis by {segment_col}:\")\n",
    "            print(revenue_by_segment)\n",
    "            \n",
    "            # Visualize\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "            fig.suptitle(f'Revenue Analysis by {segment_col}', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Total revenue by segment\n",
    "            sns.barplot(x=revenue_by_segment['Total Revenue'], y=revenue_by_segment.index, ax=axes[0])\n",
    "            axes[0].set_title('Total Revenue')\n",
    "            axes[0].set_xlabel('Revenue ($)')\n",
    "            \n",
    "            # Average transaction by segment\n",
    "            sns.barplot(x=revenue_by_segment['Avg Transaction'], y=revenue_by_segment.index, ax=axes[1])\n",
    "            axes[1].set_title('Average Transaction Value')\n",
    "            axes[1].set_xlabel('Amount ($)')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"Cannot merge datasets - customer_id column not found in both tables\")\n",
    "    print(f\"Sales columns: {sales_df.columns.tolist()}\")\n",
    "    print(f\"Customer columns: {customers_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf842b50",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "🎉 **Demo Complete!**\n",
    "\n",
    "In this notebook, we successfully demonstrated D2O (Databricks-to-Open) Delta Sharing as a recipient:\n",
    "\n",
    "✅ **What we accomplished:**\n",
    "1. Loaded credentials from environment variable\n",
    "2. Connected to the Delta Sharing endpoint\n",
    "3. Listed available shares, schemas, and tables\n",
    "4. Queried shared data using pandas\n",
    "5. Performed data analysis and generated summary statistics\n",
    "6. Created multiple visualizations using seaborn and matplotlib\n",
    "7. Merged datasets for advanced analytics\n",
    "\n",
    "**Key Benefits of D2O Delta Sharing:**\n",
    "- 🚀 **No Data Duplication**: Access live data without copying\n",
    "- 🔒 **Secure**: Token-based authentication\n",
    "- ⚡ **Real-time**: Always get the latest data from provider\n",
    "- 💰 **Cost-effective**: No storage costs for recipients\n",
    "- 🛠️ **Tool Agnostic**: Use any tool that supports Delta Sharing (Python, Power BI, Tableau, etc.)\n",
    "- 🌐 **Open Standard**: Based on open Delta Sharing protocol\n",
    "\n",
    "**Next Steps:**\n",
    "- Explore more complex queries and aggregations\n",
    "- Integrate with your existing data pipelines\n",
    "- Build dashboards using Power BI or other BI tools\n",
    "- Set up automated reporting workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55dd707",
   "metadata": {},
   "source": [
    "## 📚 Additional Resources\n",
    "\n",
    "### Documentation\n",
    "- **[START-HERE.md](../START-HERE.md)** - Quick navigation guide\n",
    "- **[README-D2O-DEMO.md](../README-D2O-DEMO.md)** - Complete setup instructions\n",
    "- **[QUICKSTART-D2O.md](../QUICKSTART-D2O.md)** - Quick reference card\n",
    "- **[ARCHITECTURE-D2O.md](../ARCHITECTURE-D2O.md)** - System architecture\n",
    "- **[EXPECTED-OUTPUT.md](../EXPECTED-OUTPUT.md)** - What to expect\n",
    "\n",
    "### External Links\n",
    "- [Databricks Delta Sharing Docs](https://docs.databricks.com/delta-sharing/)\n",
    "- [Delta Sharing Protocol](https://github.com/delta-io/delta-sharing)\n",
    "- [Python delta-sharing Library](https://github.com/delta-io/delta-sharing/tree/main/python)\n",
    "\n",
    "### Troubleshooting\n",
    "If you encounter issues:\n",
    "1. Check container logs: `docker logs d2o-demo`\n",
    "2. Verify token expiration in config.share\n",
    "3. Review provider notebook for share/recipient setup\n",
    "4. See troubleshooting section in README-D2O-DEMO.md\n",
    "\n",
    "---\n",
    "**© 2025 Databricks, Inc. All rights reserved.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
